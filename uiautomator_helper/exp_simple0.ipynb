{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "from collections import defaultdict \n",
    "import numpy as np\n",
    "import editdistance\n",
    "import random\n",
    "\n",
    "EMBEDDING_DIM = 8\n",
    "MAX_TARGET_LENGTH = 30\n",
    "\n",
    "MAXN_STATE_NODES = 100 # maximum number of state nodes used\n",
    "MAX_TOKEN_LENGTH = 60 # maximum token length padded to\n",
    "\n",
    "NODE_KEY_LIST = [ \n",
    "    # slot names (keys) of a node to add as features\n",
    "    \"index\", # integer\n",
    "    \"bounds\", # interval\n",
    "    \"resource-id\", \"class\", # formatted string\n",
    "]\n",
    "NODE_KEY_DICT = {NODE_KEY_LIST[i]:i for i in range(len(NODE_KEY_LIST))}\n",
    "\n",
    "CHAR_LIST = [\"<PAD>\", \"<UNK>\"] +\\\n",
    "list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\") +\\\n",
    "list(\"abcdefghijklmnopqrstuvwxyz\") +\\\n",
    "list(\"0123456789\") +\\\n",
    "list(\"`~!@#$%^&*()_+-={}|[]:;'',.<>/?\") +\\\n",
    "[\"\\\\\"] + ['\"']\n",
    "CHAR_DICT = defaultdict(\n",
    "    lambda:CHAR_LIST.index(\"<UNK>\"), \n",
    "    {CHAR_LIST[i]:i for i in range(len(CHAR_LIST))}\n",
    ")\n",
    "\n",
    "PADDING_NODE_VECTOR = [ [CHAR_DICT[\"<PAD>\"] for _ in range(MAX_TOKEN_LENGTH)] for _ in range(len(NODE_KEY_LIST))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific method for target encoding\n",
    "# similar to get_node_vector but without the node assumption\n",
    "# arg_node is a list of strings\n",
    "def get_sentence_vector(arg_sent):\n",
    "    sent_vector = []\n",
    "    for j in range(len(arg_sent)):\n",
    "        chars_j = list(arg_sent[j])\n",
    "        # get the indices for every char\n",
    "        inds_j = [CHAR_DICT[chars_j[k]] for k in range( min(MAX_TOKEN_LENGTH,len(chars_j)) )]\n",
    "        # pad the inds\n",
    "        inds_j += [CHAR_DICT[\"<PAD>\"]] * ( MAX_TOKEN_LENGTH-len(inds_j) )\n",
    "        sent_vector.append(inds_j)\n",
    "    return sent_vector\n",
    "\n",
    "# arg_node is a gui element object\n",
    "# (element from action list)\n",
    "def get_element_vector(arg_elem):\n",
    "    elem_vector = []\n",
    "    for j in range(len(NODE_KEY_LIST)):\n",
    "        key_j = NODE_KEY_LIST[j]\n",
    "        str_j = str(arg_elem.attributes[key_j])\n",
    "        chars_j = list(str_j)\n",
    "        # get the indices for every char\n",
    "        inds_j = [CHAR_DICT[chars_j[k]] for k in range( min(MAX_TOKEN_LENGTH,len(chars_j)) )]\n",
    "        # pad the inds\n",
    "        inds_j += [CHAR_DICT[\"<PAD>\"]] * ( MAX_TOKEN_LENGTH-len(inds_j) )\n",
    "        elem_vector.append(inds_j)\n",
    "    return elem_vector\n",
    "\n",
    "# arg_node is a ui element object\n",
    "# (node from state)\n",
    "def get_node_vector(arg_node):\n",
    "    node_vector = []\n",
    "    for j in range(len(NODE_KEY_LIST)):\n",
    "        key_j = NODE_KEY_LIST[j]\n",
    "        str_j = str(arg_node.attributes[key_j].value)\n",
    "        chars_j = list(str_j)\n",
    "        # get the indices for every char\n",
    "        inds_j = [CHAR_DICT[chars_j[k]] for k in range( min(MAX_TOKEN_LENGTH,len(chars_j)) )]\n",
    "        # pad the inds\n",
    "        inds_j += [CHAR_DICT[\"<PAD>\"]] * ( MAX_TOKEN_LENGTH-len(inds_j) )\n",
    "        node_vector.append(inds_j)\n",
    "    return node_vector\n",
    "\n",
    "# a state here is a windows hierarchy string\n",
    "def get_state_matrix(arg_wh):\n",
    "    state_nodes = minidom.parseString(arg_wh).getElementsByTagName('node')\n",
    "    state_matrix = []\n",
    "    for i in range( min(MAXN_STATE_NODES,len(state_nodes)) ):\n",
    "        state_vector = []\n",
    "        node_i = state_nodes[i]\n",
    "        node_vector_i = get_node_vector(node_i)\n",
    "        state_matrix.append(node_vector_i)\n",
    "    # pad the state matrix\n",
    "    state_matrix += [PADDING_NODE_VECTOR] * ( MAXN_STATE_NODES-len(state_matrix) )\n",
    "    return state_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Agent\n",
    "- UniversalTokenEncoder: relu\n",
    "- StateEncoder: relu\n",
    "- TargetEncoder: relu\n",
    "- ActionEncoder: sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "torch version: 1.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: {}\".format(device))\n",
    "print(\"torch version: {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniversalTokenEncoder(nn.Module):\n",
    "    def __init__(self, arg_embedding_dim):\n",
    "        super(UniversalTokenEncoder, self).__init__()\n",
    "        self.embedding_dim = arg_embedding_dim\n",
    "        self.char_embedding = nn.Embedding(\n",
    "            num_embeddings=len(CHAR_LIST),\n",
    "            embedding_dim=arg_embedding_dim,\n",
    "        )\n",
    "        self.n_kernels = [10, 10, 10]\n",
    "        self.kernel_sizes = [1, 2, 3]\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(\n",
    "                in_channels=arg_embedding_dim, \n",
    "                out_channels=self.n_kernels[i], \n",
    "                kernel_size=self.kernel_sizes[i], \n",
    "                padding=0\n",
    "            )\n",
    "            for i in range(len(self.kernel_sizes))\n",
    "        ])\n",
    "        self.pools = nn.ModuleList([\n",
    "            nn.MaxPool1d(MAX_TOKEN_LENGTH+1-self.kernel_sizes[i], padding=0)\n",
    "            for i in range(len(self.kernel_sizes))\n",
    "        ])\n",
    "        self.linear = nn.Linear(sum(self.n_kernels), arg_embedding_dim)\n",
    "        \n",
    "    # input a batch of sequences (high-dimensional)\n",
    "    # arg_seqs: (B=1, ??, len(NODE_KEY_LIST) or MAX_TARGET_LENGTH, MAX_TOKEN_LENGTH)\n",
    "    # ??=MAXN_STATE_NODES if encoding state matrix\n",
    "    # ??=1 if encoding the target\n",
    "    # ??=others if encoding an action list\n",
    "    def forward(self, arg_seqs):\n",
    "        B = arg_seqs.shape[0]\n",
    "        tmpn_nodes = arg_seqs.shape[1]\n",
    "        # tmp_dim0 = B * tmpn_nodes * len(NODE_KEY_LIST)\n",
    "        tmp_dim0 = B * tmpn_nodes * arg_seqs.shape[2]\n",
    "        assert B==1\n",
    "        # first fold the first 3 dimensions\n",
    "        tmp0 = arg_seqs.view(tmp_dim0, MAX_TOKEN_LENGTH) # (dim0, MAX_TOKEN_LENGTH)\n",
    "        tmp1 = self.char_embedding(tmp0) # (dim0, MAX_TOKEN_LENGTH, embedding_dim)\n",
    "        tmp2 = tmp1.transpose(1,2) # channel goes first for conv, (dim0, embedding_dim, MAX_TOKEN_LENGTH)\n",
    "        # (dim0, n_kernels, MAX_TOKEN_LENGTH-i)\n",
    "        tmp3s = [\n",
    "            F.relu(self.convs[i](tmp2))\n",
    "            for i in range(len(self.convs))\n",
    "        ]\n",
    "        # (dim0, n_kernels, 1)\n",
    "        tmp4s = [\n",
    "            self.pools[i](tmp3s[i])\n",
    "            for i in range(len(tmp3s))\n",
    "        ]\n",
    "        # (dim0, n_kernels)\n",
    "        tmp5s = [\n",
    "            tmp4s[i].view(tmp_dim0, self.n_kernels[i])\n",
    "            for i in range(len(tmp4s))\n",
    "        ]\n",
    "        tmp6 = torch.cat(tmp5s, 1) # (dim0, sum(n_kernels))\n",
    "        tmp7 = F.relu(self.linear(tmp6)) # (dim0, embedding_dim)\n",
    "        # unfold back to original shape\n",
    "        # which is (B=1, ??={MAXN_STATE_NODES,1,others}, len(NODE_KEY_LIST) or MAX_TARGET_LENGTH, embedding_dim)\n",
    "        # tmp8 = tmp7.view(B, tmpn_nodes, len(NODE_KEY_LIST), self.embedding_dim)\n",
    "        tmp8 = tmp7.view(B, tmpn_nodes, arg_seqs.shape[2], self.embedding_dim)\n",
    "        return tmp8\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateEncoder(nn.Module):\n",
    "    def __init__(self, arg_embedding_dim):\n",
    "        super(StateEncoder, self).__init__()\n",
    "        self.embedding_dim = arg_embedding_dim\n",
    "        self.n_kernels = [10, 10, 10]\n",
    "        self.kernel_sizes = [(1,len(NODE_KEY_LIST)), (2,len(NODE_KEY_LIST)), (3,len(NODE_KEY_LIST))]\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(\n",
    "                in_channels=arg_embedding_dim, \n",
    "                out_channels=self.n_kernels[i], \n",
    "                kernel_size=self.kernel_sizes[i], \n",
    "                padding=0\n",
    "            )\n",
    "            for i in range(len(self.kernel_sizes))\n",
    "        ])\n",
    "        self.pools = nn.ModuleList([\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=(\n",
    "                    MAXN_STATE_NODES+1-self.kernel_sizes[i][0],\n",
    "                    len(NODE_KEY_LIST)+1-self.kernel_sizes[i][1],\n",
    "                ), \n",
    "                padding=0\n",
    "            )\n",
    "            for i in range(len(self.kernel_sizes))\n",
    "        ])\n",
    "        self.linear = nn.Linear(sum(self.n_kernels), arg_embedding_dim)\n",
    "        \n",
    "    # input a batch of sequences (high-dimensional)\n",
    "    # arg_seqs: (B=1, ??, len(NODE_KEY_LIST), embedding_dim)\n",
    "    # ??=MAXN_STATE_NODES since it's encoding state matrix\n",
    "    def forward(self, arg_seqs):\n",
    "        B = arg_seqs.shape[0]\n",
    "        tmpn_nodes = arg_seqs.shape[1]\n",
    "        assert B==1\n",
    "        assert tmpn_nodes==MAXN_STATE_NODES\n",
    "        # permute for conv\n",
    "        tmp0 = arg_seqs.permute(0,3,1,2) # (B=1, embedding_dim, ??, len(NODE_KEY_LIST))\n",
    "        # (B=1, n_kernels, ??-i, len(NODE_KEY_LIST)-i)\n",
    "        tmp1s = [\n",
    "            F.relu(self.convs[i](tmp0))\n",
    "            for i in range(len(self.convs))\n",
    "        ]\n",
    "        # (B=1, n_kernels, 1, 1)\n",
    "        tmp2s = [\n",
    "            self.pools[i](tmp1s[i])\n",
    "            for i in range(len(tmp1s))\n",
    "        ]\n",
    "        # (B=1, n_kernels)\n",
    "        tmp3s = [\n",
    "            tmp2s[i].view(B, self.n_kernels[i])\n",
    "            for i in range(len(tmp2s))\n",
    "        ]\n",
    "        tmp4 = torch.cat(tmp3s, 1) # (B, sum(n_kernels))\n",
    "        tmp5 = F.relu(self.linear(tmp4)) # (B, embedding_dim)\n",
    "        return tmp5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetEncoder(nn.Module):\n",
    "    def __init__(self, arg_embedding_dim):\n",
    "        super(TargetEncoder, self).__init__()\n",
    "        self.embedding_dim = arg_embedding_dim\n",
    "        self.n_kernels = [10, 10, 10]\n",
    "        self.kernel_sizes = [1, 2, 3]\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(\n",
    "                in_channels=arg_embedding_dim, \n",
    "                out_channels=self.n_kernels[i], \n",
    "                kernel_size=self.kernel_sizes[i], \n",
    "                padding=0\n",
    "            )\n",
    "            for i in range(len(self.kernel_sizes))\n",
    "        ])\n",
    "        self.pools = nn.ModuleList([\n",
    "            nn.MaxPool1d(\n",
    "                kernel_size=(\n",
    "                    MAX_TARGET_LENGTH+1-self.kernel_sizes[i],\n",
    "                ), \n",
    "                padding=0\n",
    "            )\n",
    "            for i in range(len(self.kernel_sizes))\n",
    "        ])\n",
    "        self.linear = nn.Linear(sum(self.n_kernels), arg_embedding_dim)\n",
    "        \n",
    "    # input a batch of sequences (high-dimensional)\n",
    "    # arg_seqs: (B=1, ??, MAX_TARGET_LENGTH, embedding_dim)\n",
    "    # ??=1 since it's encoding a target\n",
    "    def forward(self, arg_seqs):\n",
    "        B = arg_seqs.shape[0]\n",
    "        tmpn_nodes = arg_seqs.shape[1]\n",
    "        tmp_dim0 = B * tmpn_nodes\n",
    "        assert B==1\n",
    "        assert tmpn_nodes==1\n",
    "        # action nodes are encoded separately, so change the view first\n",
    "        # (dim0, MAX_TARGET_LENGTH, embedding_dim)\n",
    "        # -> (dim0, embedding_dim, len(NODE_KEY_LIST))\n",
    "        tmp0 = arg_seqs.view(tmp_dim0, MAX_TARGET_LENGTH, self.embedding_dim).transpose(1,2)\n",
    "        # (dim0, n_kernels, MAX_TARGET_LENGTH-i)\n",
    "        tmp1s = [\n",
    "            F.relu(self.convs[i](tmp0))\n",
    "            for i in range(len(self.convs))\n",
    "        ]\n",
    "        # (dim0, n_kernels, 1)\n",
    "        tmp2s = [\n",
    "            self.pools[i](tmp1s[i])\n",
    "            for i in range(len(tmp1s))\n",
    "        ]\n",
    "        # (dim0, n_kernels)\n",
    "        tmp3s = [\n",
    "            tmp2s[i].view(tmp_dim0, self.n_kernels[i])\n",
    "            for i in range(len(tmp2s))\n",
    "        ]\n",
    "        tmp4 = torch.cat(tmp3s, 1) # (dim0, sum(n_kernels))\n",
    "        tmp5 = F.relu(self.linear(tmp4)) # (dim0, embedding_dim)\n",
    "        tmp6 = tmp5.view(B, tmpn_nodes, self.embedding_dim) # (B=1, ??, embedding_dim)\n",
    "        return tmp6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: ActionEncoder is actually encoding a list of actions\n",
    "#       not a single action\n",
    "class ActionEncoder(nn.Module):\n",
    "    def __init__(self, arg_embedding_dim):\n",
    "        super(ActionEncoder, self).__init__()\n",
    "        self.embedding_dim = arg_embedding_dim\n",
    "        self.n_kernels = [10, 10, 10]\n",
    "        self.kernel_sizes = [1, 2, 3]\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(\n",
    "                in_channels=arg_embedding_dim, \n",
    "                out_channels=self.n_kernels[i], \n",
    "                kernel_size=self.kernel_sizes[i], \n",
    "                padding=0\n",
    "            )\n",
    "            for i in range(len(self.kernel_sizes))\n",
    "        ])\n",
    "        self.pools = nn.ModuleList([\n",
    "            nn.MaxPool1d(\n",
    "                kernel_size=(\n",
    "                    len(NODE_KEY_LIST)+1-self.kernel_sizes[i],\n",
    "                ), \n",
    "                padding=0\n",
    "            )\n",
    "            for i in range(len(self.kernel_sizes))\n",
    "        ])\n",
    "        self.linear_w = nn.Linear(sum(self.n_kernels), arg_embedding_dim) # weight\n",
    "        self.linear_b = nn.Linear(sum(self.n_kernels), 1) # bias\n",
    "        \n",
    "    # input a batch of sequences (high-dimensional)\n",
    "    # arg_seqs: (B=1, ??, len(NODE_KEY_LIST), embedding_dim)\n",
    "    # ??=others since it's encoding an action list\n",
    "    def forward(self, arg_seqs):\n",
    "        B = arg_seqs.shape[0]\n",
    "        tmpn_nodes = arg_seqs.shape[1]\n",
    "        tmp_dim0 = B * tmpn_nodes\n",
    "        assert B==1\n",
    "        # action nodes are encoded separately, so change the view first\n",
    "        # (dim0, len(NODE_KEY_LIST), embedding_dim)\n",
    "        # -> (dim0, embedding_dim, len(NODE_KEY_LIST))\n",
    "        tmp0 = arg_seqs.view(tmp_dim0, len(NODE_KEY_LIST), self.embedding_dim).transpose(1,2)\n",
    "        # (dim0, n_kernels, len(NODE_KEY_LIST)-i)\n",
    "        tmp1s = [\n",
    "            F.relu(self.convs[i](tmp0))\n",
    "            for i in range(len(self.convs))\n",
    "        ]\n",
    "        # (dim0, n_kernels, 1)\n",
    "        tmp2s = [\n",
    "            self.pools[i](tmp1s[i])\n",
    "            for i in range(len(tmp1s))\n",
    "        ]\n",
    "        # (dim0, n_kernels)\n",
    "        tmp3s = [\n",
    "            tmp2s[i].view(tmp_dim0, self.n_kernels[i])\n",
    "            for i in range(len(tmp2s))\n",
    "        ]\n",
    "        tmp4 = torch.cat(tmp3s, 1) # (dim0, sum(n_kernels))\n",
    "        tmp5_w = F.relu(self.linear_w(tmp4)) # (dim0, embedding_dim)\n",
    "        tmp5_b = F.relu(self.linear_b(tmp4)) # (dim0, embedding_dim)\n",
    "        tmp6_w = tmp5_w.view(B, tmpn_nodes, self.embedding_dim) # (B=1, ??, embedding_dim)\n",
    "        tmp6_b = tmp5_b.view(B, tmpn_nodes, 1) # (B=1, ??, 1)\n",
    "        return tmp6_w, tmp6_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralAgent(nn.Module):\n",
    "    def __init__(self, arg_embedding_dim):\n",
    "        super(NeuralAgent, self).__init__()\n",
    "        self.embedding_dim = arg_embedding_dim\n",
    "        self.universal_token_encoder = UniversalTokenEncoder(arg_embedding_dim)\n",
    "        self.state_encoder = StateEncoder(arg_embedding_dim)\n",
    "        self.target_encoder = TargetEncoder(arg_embedding_dim)\n",
    "        self.action_encoder = ActionEncoder(arg_embedding_dim)\n",
    "        \n",
    "        self.hidden0 = nn.Linear(arg_embedding_dim*2, arg_embedding_dim)\n",
    "        \n",
    "    # arg_state: (B=1, ??=MAXN_STATE_NODES, len(NODE_KEY_LIST), MAX_TOKEN_LENGTH)\n",
    "    # arg_target: (B=1, ??=1, MAX_TARGET_LENGTH, MAX_TOKEN_LENGTH)\n",
    "    def compute_preference_matrix(self, arg_state, arg_target):\n",
    "        B_state = arg_state.shape[0]\n",
    "        B_target = arg_target.shape[0]\n",
    "        assert B_state==1\n",
    "        assert B_target==1\n",
    "        \n",
    "        # fixme: only support 1 target at a time\n",
    "        n_targets = arg_target.shape[1]\n",
    "        assert n_targets==1 \n",
    "        \n",
    "        tmp0_state = self.universal_token_encoder(arg_state) # (B=1, ??, len(NODE_KEY_LIST), embedding_dim)\n",
    "        tmp0_target = self.universal_token_encoder(arg_target) # (B=1, ??, MAX_TARGET_LENGTH, embedding_dim)\n",
    "        tmp1_state = self.state_encoder(tmp0_state) # (B=1, embedding_dim)\n",
    "        tmp1_target = self.target_encoder(tmp0_target) # (B=1, ??, embedding_dim)\n",
    "        tmp2_state = tmp1_state\n",
    "        \n",
    "        # fixme: only support 1 target at a time\n",
    "        tmp2_target = tmp1_target.view(B_target, self.embedding_dim) # (B=1, embedding_dim)\n",
    "        \n",
    "        tmp3 = torch.cat([tmp2_state, tmp2_target], 1) # (B=1, embedding_dim * 2)\n",
    "        tmp4 = torch.sigmoid(self.hidden0(tmp3)) # (B=1, embedding_dim)\n",
    "        return tmp4\n",
    "\n",
    "    # arg_action: (B=1, ??=others, len(NODE_KEY_LIST), MAX_TOKEN_LENGTH)\n",
    "    def compute_action_matrix(self, arg_action):\n",
    "        B = arg_action.shape[0]\n",
    "        tmp0 = self.universal_token_encoder(arg_action) # (B=1, ??, len(NODE_KEY_LIST), embedding_dim)\n",
    "        tmp1_w, tmp1_b = self.action_encoder(tmp0) # (B=1, ??, embedding_dim)\n",
    "        return tmp1_w, tmp1_b\n",
    "    \n",
    "    def compute_similarity_matrix(self, arg_pref, arg_w, arg_b):\n",
    "        # arg_pref: (B=1, embedding_dim)\n",
    "        # arg_w: (B=1, ??, embedding_dim)\n",
    "        # arg_b: (B=1, ??, 1)\n",
    "        B = arg_pref.shape[0]\n",
    "        A = arg_w.shape[1]\n",
    "        assert B==1\n",
    "        assert B==arg_w.shape[0]\n",
    "        assert B==arg_b.shape[0]\n",
    "        assert A==arg_b.shape[1]\n",
    "        tmp0 = arg_pref.view((B, self.embedding_dim, 1)) # (B=1, embedding_dim, 1)\n",
    "        tmp1 = torch.matmul(arg_w, tmp0) # (B=1, ??, 1)\n",
    "        tmp2 = torch.add(tmp1, arg_b)\n",
    "        tmp3 = tmp2.view((B,A)) # (B=1, ??)\n",
    "        tmp4 = F.log_softmax(tmp3, dim=1)\n",
    "        return tmp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_filter(arg_alist):\n",
    "    # remove system Back/Home gui elements\n",
    "    tmp0 = [\n",
    "        arg_alist[i] \n",
    "        for i in range(len(arg_alist)) \n",
    "        if \"com.android.systemui\" not in arg_alist[i].attributes[\"resource-id\"]\n",
    "    ]\n",
    "    return tmp0\n",
    "#     tmp1 = [\n",
    "#         tmp0[i] \n",
    "#         for i in range(len(tmp0)) \n",
    "#         if \"android.widget.EditText\" not in tmp0[i].attributes[\"class\"]\n",
    "#     ]\n",
    "#     return tmp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(arg_config):\n",
    "    batch_loss = 0.\n",
    "    \n",
    "    for ep in range(arg_config[\"n_episodes\"]):\n",
    "        print(\"# episode {}\".format(ep))\n",
    "        epsilon = arg_config[\"epsilon\"](ep)\n",
    "        print(\"  epsilon={}\".format(epsilon))\n",
    "        \n",
    "        # reset\n",
    "        arg_config[\"environment\"].launch_app()\n",
    "        \n",
    "        rollout_outputs = []\n",
    "        rollout_actions = []\n",
    "        rollout_action_ids = []\n",
    "        rollout_rewards = []\n",
    "\n",
    "        for i in range(arg_config[\"maxn_steps\"]):\n",
    "            \n",
    "            # should wrap [] to make B=1\n",
    "            # (B=1, ??=MAXN_STATE_NODES, len(NODE_KEY_LIST), MAX_TOKEN_LENGTH)\n",
    "            i_observation = arg_config[\"environment\"].get_current_state()\n",
    "            inp_observation = np.asarray([get_state_matrix(i_observation)])\n",
    "            its_observation = Variable(torch.tensor(inp_observation, dtype=torch.long).to(device))\n",
    "            \n",
    "            # (B=1, ??=others, len(NODE_KEY_LIST), MAX_TOKEN_LENGTH)\n",
    "            # i_ids = arg_config[\"environment\"].get_available_actionable_elements(i_observation)\n",
    "            i_ids = action_filter(\n",
    "                arg_config[\"environment\"].get_available_actionable_elements(i_observation)\n",
    "            )\n",
    "            inp_ids = np.asarray([[\n",
    "                get_element_vector(i_ids[j])\n",
    "                for j in range(len(i_ids))\n",
    "            ]])\n",
    "            its_ids = Variable(torch.tensor(inp_ids, dtype=torch.long).to(device))\n",
    "            \n",
    "            # (B=1, ??=1, len(NODE_KEY_LIST), MAX_TOKEN_LENGTH)\n",
    "            inp_target = np.asarray([[\n",
    "                get_sentence_vector(arg_config[\"target\"])\n",
    "            ]])\n",
    "            its_target = Variable(torch.tensor(inp_target, dtype=torch.long).to(device))\n",
    "            \n",
    "            arg_config[\"agent\"].train()\n",
    "            its_preference_matrix = arg_config[\"agent\"].compute_preference_matrix(its_observation, its_target) # (B=1, embedding_dim)\n",
    "            its_w, its_b = arg_config[\"agent\"].compute_action_matrix(its_ids) # (B=1, ??, embedding_dim)\n",
    "            # compute similarity\n",
    "            # (B=1, ??)\n",
    "            its_sim = arg_config[\"agent\"].compute_similarity_matrix(\n",
    "                its_preference_matrix,\n",
    "                its_w, its_b\n",
    "            )\n",
    "            \n",
    "            i_output = its_sim.flatten().exp().tolist() # (??,)\n",
    "\n",
    "            if random.random()<epsilon:\n",
    "                # explore\n",
    "                selected_action_id = random.choice(list(range(len(i_output))))\n",
    "            else:\n",
    "                # exploit\n",
    "                selected_action_id = np.argmax(i_output)\n",
    "\n",
    "            # keep track\n",
    "            rollout_outputs.append(its_sim)\n",
    "            rollout_actions.append(i_ids[selected_action_id])\n",
    "            rollout_action_ids.append(selected_action_id) # action is action_id in this case\n",
    "            \n",
    "            arg_config[\"environment\"].perform_action(i_ids[selected_action_id])\n",
    "            i_reward = None\n",
    "            rlist = arg_config[\"environment\"].get_reached_goal_states(\"train\")\n",
    "            if len(rlist)>0:\n",
    "                # goal state!\n",
    "                i_reward = +1.0\n",
    "                rollout_rewards.append(i_reward)\n",
    "                break\n",
    "            else:\n",
    "                if i==arg_config[\"maxn_steps\"]-1:\n",
    "                    i_reward = -0.1\n",
    "                    # i_reward = +0.01\n",
    "                    # i_reward = 0.0\n",
    "                else:\n",
    "                    ja = rollout_actions[-1].attributes\n",
    "                    qa = [p.attributes for p in rollout_actions[:-1]]\n",
    "                    if ja in qa:\n",
    "                        i_reward = -0.1\n",
    "                        # i_reward = +0.0001\n",
    "                        # i_reward = 0.0\n",
    "                    else:\n",
    "                        # check for partial rewards\n",
    "                        # fixme: manually assigned, which should have been the job of static analysis\n",
    "                        j_observation = arg_config[\"environment\"].get_current_state()\n",
    "                        if arg_config[\"partial_target\"] in j_observation:\n",
    "                            # reward adjustment: if duplicate action, reduce!\n",
    "                            i_reward = +1.0\n",
    "                        elif \"âˆž\" in j_observation:\n",
    "                            # reward adjustment: if duplicate action, reduce!\n",
    "                            i_reward = +1.0\n",
    "                        else:\n",
    "                            # i_reward = 0.01\n",
    "                            i_reward = 0.0\n",
    "                rollout_rewards.append(i_reward)\n",
    "                \n",
    "        # reward-length penalization\n",
    "        rollout_rewards = [p+(arg_config[\"maxn_steps\"]-len(rollout_rewards)) for p in rollout_rewards]\n",
    "        print(\"  steps={}, rewards={}, actions={}\".format(i, rollout_rewards, rollout_action_ids))\n",
    "        rollout_loss = []\n",
    "        for i in range(len(rollout_outputs)):\n",
    "            current_return = 0.\n",
    "            for j in range(i,len(rollout_outputs)):\n",
    "                df = 0.9**(j-i)\n",
    "                current_return += df * rollout_rewards[j]\n",
    "            rollout_loss.append( current_return * (-rollout_outputs[i][0][rollout_action_ids[i]]) )\n",
    "\n",
    "        ep_loss = sum(rollout_loss)\n",
    "        batch_loss += ep_loss\n",
    "        if (ep+1)%arg_config[\"batch_size\"]==0:\n",
    "            print(\"  update policy\")\n",
    "            arg_config[\"optimizer\"].zero_grad()\n",
    "            batch_loss = batch_loss / arg_config[\"batch_size\"]\n",
    "            batch_loss.backward()\n",
    "            arg_config[\"optimizer\"].step()\n",
    "            batch_loss = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] | 2020-12-27 03:24:49 PM | analyzer.app_simple0 | Adb is running with root priviledges now!\n",
      "[INFO] | 2020-12-27 03:24:49 PM | analyzer.app_simple0 | Old logcat messages cleared!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m[#] Analysis started at: 2020-12-27 03:24:49 PM\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] | 2020-12-27 03:24:50 PM | analyzer.app_simple0 | APK installtion done for app_simple0.apk\n",
      "[INFO] | 2020-12-27 03:24:50 PM | analyzer.app_simple0 | Kill the current app if already spawned!\n",
      "[INFO] | 2020-12-27 03:24:51 PM | analyzer.app_simple0 | APK is already killed\n",
      "[INFO] | 2020-12-27 03:24:51 PM | analyzer.app_simple0 | Spawning the current app\n",
      "[INFO] | 2020-12-27 03:24:53 PM | analyzer.app_simple0 | Old logcat messages cleared!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from main import *\n",
    "\n",
    "CURR_DIR = os.path.dirname(os.getcwd())\n",
    "OUTPUT_DIR = os.path.join(CURR_DIR, \"results\")\n",
    "\n",
    "args = {\n",
    "    \"path\": \"../test/com.github.cetoolbox_11/app_simple0.apk\",\n",
    "    \"output\": \"../results/\",\n",
    "}\n",
    "\n",
    "if args[\"path\"] is not None:\n",
    "    pyaxmlparser_apk = APK(args[\"path\"])\n",
    "    apk_base_name = os.path.splitext(os.path.basename(args[\"path\"]))[0]\n",
    "\n",
    "else:\n",
    "    parser.print_usage()\n",
    "\n",
    "if args[\"output\"] is not None:\n",
    "    OUTPUT_DIR = args[\"output\"]\n",
    "\n",
    "output_dir = os.path.join(OUTPUT_DIR, apk_base_name)\n",
    "\n",
    "if os.path.exists(output_dir):\n",
    "    rmtree(output_dir)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "# Setting the path for log file\n",
    "log_path = os.path.join(output_dir, 'analysis.log')\n",
    "log = init_logging('analyzer.%s' % apk_base_name, log_path, file_mode='w', console=True)\n",
    "\n",
    "# Record analysis start time\n",
    "now = datetime.datetime.now()\n",
    "analysis_start_time = now.strftime(DATE_FORMAT)\n",
    "info('Analysis started at: %s' % analysis_start_time)\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the serial for the device attached to ADB\n",
    "device_serial = get_device_serial(log)\n",
    "\n",
    "if device_serial is None:\n",
    "    log.warning(\"Device is not connected!\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Initialize the uiautomator device object using the device serial\n",
    "uiautomator_device = u2.connect(device_serial)\n",
    "run_adb_as_root(log)\n",
    "apk = Apk(args[\"path\"], uiautomator_device, log)\n",
    "apk.launch_app()\n",
    "# to track some goal state at startup, you don't have to do this\n",
    "apk.clean_logcat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] | 2020-12-27 03:24:53 PM | analyzer.app_simple0 | Kill the current app if already spawned!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# episode 0\n",
      "  epsilon=0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] | 2020-12-27 03:24:54 PM | analyzer.app_simple0 | APK killed\n",
      "[INFO] | 2020-12-27 03:24:54 PM | analyzer.app_simple0 | Spawning the current app\n",
      "[INFO] | 2020-12-27 03:25:06 PM | analyzer.app_simple0 | Kill the current app if already spawned!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  steps=3, rewards=[0.0, 0.0, 0.0, -0.1], actions=[10, 12, 2, 1]\n",
      "# episode 1\n",
      "  epsilon=0.9440624999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] | 2020-12-27 03:25:06 PM | analyzer.app_simple0 | APK killed\n",
      "[INFO] | 2020-12-27 03:25:06 PM | analyzer.app_simple0 | Spawning the current app\n",
      "[INFO] | 2020-12-27 03:25:18 PM | analyzer.app_simple0 | Kill the current app if already spawned!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  steps=3, rewards=[1.0, 1.0, 0.0, -0.1], actions=[11, 6, 10, 0]\n",
      "# episode 2\n",
      "  epsilon=0.938125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] | 2020-12-27 03:25:18 PM | analyzer.app_simple0 | APK killed\n",
      "[INFO] | 2020-12-27 03:25:18 PM | analyzer.app_simple0 | Spawning the current app\n"
     ]
    }
   ],
   "source": [
    "neural_agent = NeuralAgent(EMBEDDING_DIM).to(device)\n",
    "# optimizer = torch.optim.SGD(agent.parameters(), lr=0.01)\n",
    "# optimizer = torch.optim.Adam(agent.parameters(), lr=0.01)\n",
    "optimizer = torch.optim.RMSprop(neural_agent.parameters(), lr=0.01)\n",
    "target_str = \"<com.github.cetoolbox.fragments.tabs.FlowrateActivity: void onItemSelected(android.widget.AdapterView,android.view.View,int,long)> : null\"\n",
    "target = target_str.replace(\"<\",\"#\").replace(\">\",\"#\").replace(\".\",\"#\").replace(\":\",\"#\")\\\n",
    "                   .replace(\"(\",\"#\").replace(\")\",\"#\").replace(\",\",\"#\").replace(\" \",\"#\").split(\"#\")\n",
    "target = [p for p in target if len(p.strip())>0]\n",
    "target += [[\"\"]] * ( MAX_TARGET_LENGTH-len(target) )\n",
    "partial_target = \\\n",
    "\"\"\"\n",
    "text=\"FLOWRATE\" resource-id=\"android:id/title\" class=\"android.widget.TextView\" package=\"com.github.cetoolbox\" content-desc=\"\" checkable=\"false\" checked=\"false\" clickable=\"false\" enabled=\"true\" focusable=\"false\" focused=\"false\" scrollable=\"false\" long-clickable=\"false\" password=\"false\" selected=\"true\"\n",
    "\"\"\".strip()\n",
    "config = {\n",
    "    \"environment\": apk,\n",
    "    \"agent\": neural_agent,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"maxn_steps\": 4,\n",
    "    \"n_episodes\": 100000,\n",
    "    \"epsilon\": lambda x: max(0.05, 0.95-x/160*0.95), # explore prob\n",
    "    \"batch_size\": 4,\n",
    "    \"target\": target,\n",
    "    \"partial_target\": partial_target,\n",
    "}\n",
    "rollout(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
